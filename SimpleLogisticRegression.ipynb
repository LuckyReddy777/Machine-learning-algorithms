{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cancer_data.target)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer_data.data, cancer_data.target, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9300699300699301"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.18820093e-01,  1.40622805e-01,  7.54872819e-01,\n",
       "        -3.38199490e-02, -4.47967200e-03, -3.28786865e-02,\n",
       "        -5.01428337e-02, -1.95462620e-02, -4.52970832e-03,\n",
       "        -8.27941569e-04,  8.26076655e-03,  5.12883015e-02,\n",
       "        -8.33959486e-02, -9.75325361e-02, -3.78274934e-04,\n",
       "        -7.23045980e-03, -1.10839358e-02, -2.72782297e-03,\n",
       "        -4.53722493e-04, -5.75942067e-04,  3.25358862e-01,\n",
       "        -3.20030074e-01, -3.82435275e-01, -1.04172041e-02,\n",
       "        -9.73909588e-03, -1.11880775e-01, -1.47468984e-01,\n",
       "        -4.03595375e-02, -1.98067230e-02, -9.81306195e-03]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0502595])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = my_model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0.98569443, 0.01430557]), 0),\n",
       " (array([3.56751053e-04, 9.99643249e-01]), 1),\n",
       " (array([0.00478373, 0.99521627]), 1),\n",
       " (array([9.99518703e-01, 4.81296645e-04]), 0),\n",
       " (array([0.00643432, 0.99356568]), 1),\n",
       " (array([0.01393587, 0.98606413]), 1),\n",
       " (array([7.78028787e-04, 9.99221971e-01]), 1),\n",
       " (array([0.92671704, 0.07328296]), 0),\n",
       " (array([9.99999390e-01, 6.09715489e-07]), 0),\n",
       " (array([0.98334849, 0.01665151]), 0),\n",
       " (array([2.06823095e-04, 9.99793177e-01]), 1),\n",
       " (array([4.48064631e-04, 9.99551935e-01]), 1),\n",
       " (array([0.50075497, 0.49924503]), 0),\n",
       " (array([0.00164671, 0.99835329]), 1),\n",
       " (array([9.99648927e-01, 3.51072565e-04]), 0),\n",
       " (array([0.9975453, 0.0024547]), 0),\n",
       " (array([0.00158858, 0.99841142]), 1),\n",
       " (array([0.15041747, 0.84958253]), 1),\n",
       " (array([0.02012843, 0.97987157]), 1),\n",
       " (array([0.99512194, 0.00487806]), 0),\n",
       " (array([0.58481497, 0.41518503]), 0),\n",
       " (array([0.25256987, 0.74743013]), 1),\n",
       " (array([0.0090927, 0.9909073]), 1),\n",
       " (array([0.09302327, 0.90697673]), 1),\n",
       " (array([9.99999999e-01, 1.45895412e-09]), 0),\n",
       " (array([9.99999898e-01, 1.02260208e-07]), 0),\n",
       " (array([0.13571486, 0.86428514]), 1),\n",
       " (array([9.99999996e-01, 3.76794534e-09]), 0),\n",
       " (array([0.00210147, 0.99789853]), 1),\n",
       " (array([0.02919253, 0.97080747]), 1),\n",
       " (array([0.00221988, 0.99778012]), 1),\n",
       " (array([0.0092144, 0.9907856]), 1),\n",
       " (array([1.00000000e+00, 6.69900371e-11]), 0),\n",
       " (array([0.00128217, 0.99871783]), 1),\n",
       " (array([0.05726957, 0.94273043]), 1),\n",
       " (array([0.00528094, 0.99471906]), 1),\n",
       " (array([0.02530757, 0.97469243]), 1),\n",
       " (array([6.90208241e-05, 9.99930979e-01]), 1),\n",
       " (array([0.00164574, 0.99835426]), 1),\n",
       " (array([0.00407439, 0.99592561]), 1),\n",
       " (array([6.62614284e-04, 9.99337386e-01]), 1),\n",
       " (array([0.00263211, 0.99736789]), 1),\n",
       " (array([0.00169432, 0.99830568]), 1),\n",
       " (array([0.2632279, 0.7367721]), 1),\n",
       " (array([1.68915090e-04, 9.99831085e-01]), 1),\n",
       " (array([1.00000000e+00, 5.74212776e-19]), 0),\n",
       " (array([0.99128718, 0.00871282]), 0),\n",
       " (array([0.99427342, 0.00572658]), 0),\n",
       " (array([0.98930259, 0.01069741]), 0),\n",
       " (array([0.00105645, 0.99894355]), 1),\n",
       " (array([0.01147127, 0.98852873]), 1),\n",
       " (array([0.0079652, 0.9920348]), 1),\n",
       " (array([9.99564509e-01, 4.35490660e-04]), 0),\n",
       " (array([0.00375421, 0.99624579]), 1),\n",
       " (array([0.01628694, 0.98371306]), 1),\n",
       " (array([1.00000000e+00, 6.57764021e-25]), 0),\n",
       " (array([9.99988161e-01, 1.18394019e-05]), 0),\n",
       " (array([0.00135209, 0.99864791]), 1),\n",
       " (array([0.04335244, 0.95664756]), 1),\n",
       " (array([8.35684006e-05, 9.99916432e-01]), 1),\n",
       " (array([1.00000000e+00, 1.25847301e-29]), 0),\n",
       " (array([7.11120262e-04, 9.99288880e-01]), 1),\n",
       " (array([0.95899609, 0.04100391]), 0),\n",
       " (array([0.03950598, 0.96049402]), 1),\n",
       " (array([9.43285182e-04, 9.99056715e-01]), 1),\n",
       " (array([0.69272847, 0.30727153]), 0),\n",
       " (array([0.02856836, 0.97143164]), 1),\n",
       " (array([1.86755487e-05, 9.99981324e-01]), 1),\n",
       " (array([0.99855726, 0.00144274]), 0),\n",
       " (array([0.5980518, 0.4019482]), 0),\n",
       " (array([1.13182921e-04, 9.99886817e-01]), 1),\n",
       " (array([1.33252836e-04, 9.99866747e-01]), 1),\n",
       " (array([0.00273883, 0.99726117]), 1),\n",
       " (array([5.56102525e-05, 9.99944390e-01]), 1),\n",
       " (array([0.00537015, 0.99462985]), 1),\n",
       " (array([0.88789472, 0.11210528]), 0),\n",
       " (array([0.01149442, 0.98850558]), 1),\n",
       " (array([0.00516989, 0.99483011]), 1),\n",
       " (array([9.99993959e-01, 6.04124054e-06]), 0),\n",
       " (array([9.99848797e-01, 1.51202676e-04]), 0),\n",
       " (array([2.90649778e-04, 9.99709350e-01]), 1),\n",
       " (array([0.00496775, 0.99503225]), 1),\n",
       " (array([9.99999999e-01, 1.16341854e-09]), 0),\n",
       " (array([0.04086687, 0.95913313]), 1),\n",
       " (array([5.96267064e-05, 9.99940373e-01]), 1),\n",
       " (array([0.00357728, 0.99642272]), 1),\n",
       " (array([0.0288995, 0.9711005]), 1),\n",
       " (array([0.98772274, 0.01227726]), 0),\n",
       " (array([0.00312657, 0.99687343]), 1),\n",
       " (array([0.67542893, 0.32457107]), 0),\n",
       " (array([0.00135427, 0.99864573]), 1),\n",
       " (array([0.17959667, 0.82040333]), 1),\n",
       " (array([9.99989984e-01, 1.00164796e-05]), 0),\n",
       " (array([0.01826276, 0.98173724]), 1),\n",
       " (array([1.76280268e-04, 9.99823720e-01]), 1),\n",
       " (array([7.76553094e-04, 9.99223447e-01]), 1),\n",
       " (array([9.99999998e-01, 2.13311072e-09]), 0),\n",
       " (array([8.92081503e-04, 9.99107918e-01]), 1),\n",
       " (array([1.00000000e+00, 2.92944881e-11]), 0),\n",
       " (array([0.00137865, 0.99862135]), 1),\n",
       " (array([9.99999986e-01, 1.38391293e-08]), 0),\n",
       " (array([9.99812256e-01, 1.87744413e-04]), 0),\n",
       " (array([8.62015784e-05, 9.99913798e-01]), 1),\n",
       " (array([3.18968184e-04, 9.99681032e-01]), 1),\n",
       " (array([3.75212688e-04, 9.99624787e-01]), 1),\n",
       " (array([4.78323487e-05, 9.99952168e-01]), 1),\n",
       " (array([9.99999991e-01, 8.95172071e-09]), 0),\n",
       " (array([1.00000000e+00, 1.06119445e-24]), 0),\n",
       " (array([4.77414216e-04, 9.99522586e-01]), 1),\n",
       " (array([7.26707047e-04, 9.99273293e-01]), 1),\n",
       " (array([0.00239229, 0.99760771]), 1),\n",
       " (array([0.02621753, 0.97378247]), 1),\n",
       " (array([1.00000000e+00, 9.49838637e-12]), 0),\n",
       " (array([9.99999595e-01, 4.05311805e-07]), 0),\n",
       " (array([1.00000000e+00, 2.11847485e-13]), 0),\n",
       " (array([4.61664303e-04, 9.99538336e-01]), 1),\n",
       " (array([0.03286545, 0.96713455]), 1),\n",
       " (array([1.00000000e+00, 6.66700651e-11]), 0),\n",
       " (array([0.99478998, 0.00521002]), 0),\n",
       " (array([4.74479655e-04, 9.99525520e-01]), 1),\n",
       " (array([0.00734776, 0.99265224]), 1),\n",
       " (array([9.99979793e-01, 2.02074063e-05]), 0),\n",
       " (array([0.00564474, 0.99435526]), 1),\n",
       " (array([1.00000000e+00, 5.61360631e-12]), 0),\n",
       " (array([1.40192269e-05, 9.99985981e-01]), 1),\n",
       " (array([0.04484712, 0.95515288]), 1),\n",
       " (array([1.00000000e+00, 2.26196114e-10]), 0),\n",
       " (array([0.99294736, 0.00705264]), 0),\n",
       " (array([0.00220405, 0.99779595]), 1),\n",
       " (array([0.00799966, 0.99200034]), 1),\n",
       " (array([0.30495743, 0.69504257]), 1),\n",
       " (array([5.02934872e-04, 9.99497065e-01]), 1),\n",
       " (array([0.55637344, 0.44362656]), 0),\n",
       " (array([1.17461629e-04, 9.99882538e-01]), 1),\n",
       " (array([4.46957992e-04, 9.99553042e-01]), 1),\n",
       " (array([9.99999986e-01, 1.36538419e-08]), 0),\n",
       " (array([0.6746194, 0.3253806]), 0),\n",
       " (array([9.99999964e-01, 3.60740978e-08]), 0),\n",
       " (array([0.15989484, 0.84010516]), 1),\n",
       " (array([9.99999982e-01, 1.84207819e-08]), 0),\n",
       " (array([0.00640624, 0.99359376]), 1),\n",
       " (array([8.59244159e-05, 9.99914076e-01]), 1),\n",
       " (array([1.00000000e+00, 8.19906985e-17]), 0)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(my_model.predict_proba(X_test),my_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[48,  4],\n",
       "       [ 6, 85]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 1),\n",
       " (1, 1)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in list(zip(y_test,y_pred)) if i[0] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
